# -*- coding: utf-8 -*-
"""Multivariate_MH_SS

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/158NqLd_P8ry8RWcco5VNiMERgm8PHyce
"""

from google.colab import drive
drive.mount('/content/drive')

from math import sqrt
import numpy as np
import sklearn
from sklearn.neural_network import MLPRegressor
from sklearn.ensemble import RandomForestRegressor
import pandas as pd
import matplotlib.pyplot as plt
from numpy import concatenate
from matplotlib import pyplot
from pandas import read_csv
from pandas import DataFrame
from pandas import concat
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_squared_error
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from pandas import read_csv
from datetime import datetime
from keras.layers import Bidirectional
import datetime
from keras.layers import RepeatVector
from keras.layers import TimeDistributed
from numpy import array
import time

from sklearn.externals import joblib
scaler_filename = "/content/drive/My Drive/covid project/Data/scalars/Maharashtra_moving"
scaler = joblib.load(scaler_filename) 
def rmse(pred, actual):
    # print(pred.shape)
    # print(actual)
    pred_flat = np.ndarray.flatten(pred)
    pred_un = scaler.inverse_transform(np.reshape(pred_flat,(pred_flat.shape[0],1)))
    actual_flat = np.ndarray.flatten(actual)
    actual_un = scaler.inverse_transform(np.reshape(actual_flat,(actual_flat.shape[0],1)))
    actual_flaten = []
    pred_flaten = []
    for lis in actual_un:
      actual_flaten.append(lis[0])
    for lis in pred_un:
      pred_flaten.append(lis[0])
    error = np.subtract(pred_flaten, actual_flaten)
    # print(error)
    try:
      error = np.reshape(error,(actual.shape[0],actual.shape[1]))
    except:
      pass
    sqerror= np.sum(np.square(error))/actual.shape[0]
    return np.sqrt(sqerror)

def generate_data(df_train,df_test,n_steps_in,n_steps_out):

    x_train = []
    y_train = []        
    x_test = []
    y_test = []
    n_features = 1              
    for i in range(len(df_train.index)):
        x_train.append(df_train.iloc[i,1:n_steps_in+1])
        y_train.append(df_train.iloc[i,n_steps_in+1:n_steps_in+1+n_steps_out])

    for i in range(len(df_test.index)):
        x_test.append(df_test.iloc[i,1:n_steps_in+1])
        y_test.append(df_test.iloc[i,n_steps_in+1:n_steps_in+1+n_steps_out])    

    x_train = np.array(x_train)
    x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],n_features)
    y_train = np.array(y_train)

    x_test = np.array(x_test)
    x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],n_features)
    y_test = np.array(y_test)

    return x_train,x_test,y_train,y_test


def processing_data(dfx,dfy,dfz,dfw,dfx0,dfy0,dfz0,dfw0,n_steps_in,n_steps_out):
    x_train = []
    y_train = []        
    x_test = []
    y_test = []  

    x_train1,x_test1,y_train1,y_test1 = generate_data(dfx,dfx0,n_steps_in,n_steps_out)
    x_train2,x_test2,y_train2,y_test2 = generate_data(dfy,dfy0,n_steps_in,n_steps_out)
    x_train3,x_test3,y_train3,y_test3 = generate_data(dfz,dfz0,n_steps_in,n_steps_out)
    x_train4,x_test4,y_train4,y_test4 = generate_data(dfw,dfw0,n_steps_in,n_steps_out)
    
    print(len(x_train1))
    # print(x_train1)
    print(len(x_train4))
    # print(x_train4)
    x_train = np.concatenate((x_train1,x_train2,x_train3,x_train4),axis=2)
    x_test = np.concatenate((x_test1,x_test2,x_test3,x_test4),axis=2)
    y_train = y_train1
    y_test = y_test1

    return x_train,x_test,y_train,y_test

import tensorflow as tf
early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)

def MODEL_LSTM(x_train,x_test,y_train,y_test,Num_Exp,Epochs,Hidden,batch_size,n_steps_in,n_steps_out):
        
    train_acc=np.zeros(Num_Exp)
    test_acc=np.zeros(Num_Exp)
    Step_RMSE=np.zeros([Num_Exp,n_steps_out])
    n_features = x_train.shape[-1]

    model = Sequential()
    model.add(LSTM(Hidden, activation='relu', input_shape=(n_steps_in,n_features), dropout=0.2))
    # model.add(Dense(16))
    model.add(Dense(n_steps_out))
    model.compile(optimizer='adam', loss='mse')
    model.summary()
    Best_RMSE=100000000   #Assigning a large number 
    
    start_time=time.time()
    for run in range(Num_Exp):
        print("Experiment",run+1,"in progress")
        # fit model
        history = model.fit(x_train, y_train, epochs=Epochs,batch_size=batch_size, verbose=0, shuffle=False,callbacks = [early_stopping_callback])
        
        y_predicttrain = model.predict(x_train)
        y_predicttest = model.predict(x_test)
        train_acc[run] = rmse( y_predicttrain,y_train) 
        test_acc[run] = rmse( y_predicttest, y_test) 
        if test_acc[run]<Best_RMSE:
            Best_RMSE=test_acc[run]
            Best_Predict_Test=y_predicttest
        for j in range(n_steps_out):
            Step_RMSE[run][j]=rmse(y_predicttest[:,j], y_test[:,j])
            
    print("Total time for",Num_Exp,"experiments",time.time()-start_time)
    return train_acc,test_acc,Step_RMSE,Best_Predict_Test

def MODEL_Bi_LSTM(x_train,x_test,y_train,y_test,Num_Exp,Epochs,Hidden,batch_size,n_steps_in,n_steps_out):
    
    train_acc=np.zeros(Num_Exp)
    test_acc=np.zeros(Num_Exp)
    Step_RMSE=np.zeros([Num_Exp,n_steps_out])
    n_features = x_train.shape[-1]

    model = Sequential()
    model.add(Bidirectional(LSTM(Hidden, activation='relu', dropout=0.2), input_shape=(n_steps_in,n_features)))
    # model.add(Dense(32))
    model.add(Dense(n_steps_out))
    model.compile(optimizer='adam', loss='mse')
    model.summary()
    
    Best_RMSE=100000000   #Assigning a large number 
    start_time=time.time()
    for run in range(Num_Exp):
        print("Experiment",run+1,"in progress")
        # fit model
        model.fit(x_train, y_train, epochs=Epochs,batch_size=batch_size, verbose=0, shuffle=False,callbacks = [early_stopping_callback])
        y_predicttrain = model.predict(x_train)
        y_predicttest = model.predict(x_test)
        train_acc[run] = rmse( y_predicttrain,y_train) 
        test_acc[run] = rmse( y_predicttest, y_test) 
        if test_acc[run]<Best_RMSE:
            Best_RMSE=test_acc[run]
            Best_Predict_Test=y_predicttest
        for j in range(n_steps_out):
            Step_RMSE[run][j]=rmse(y_predicttest[:,j], y_test[:,j])
            
    print("Total time for",Num_Exp,"experiments",time.time()-start_time)
    return train_acc,test_acc,Step_RMSE,Best_Predict_Test    




def MODEL_EN_DC(x_train,x_test,y_train,y_test,Num_Exp,Epochs,Hidden,batch_size,n_steps_in,n_steps_out):
    
    train_acc=np.zeros(Num_Exp)
    test_acc=np.zeros(Num_Exp)
    Step_RMSE=np.zeros([Num_Exp,n_steps_out])
    n_features = x_train.shape[-1]
    
    model = Sequential()
    model.add(LSTM(Hidden, activation='relu',input_shape=(n_steps_in,n_features), dropout=0.2)) 
    model.add(RepeatVector(n_steps_out))
    model.add(LSTM(Hidden, activation='relu', return_sequences=True, dropout=0.2))
    # model.add(TimeDistributed(Dense(16,activation='relu')))
    model.add(TimeDistributed(Dense(1,activation='relu')))
    model.compile(optimizer='adam', loss='mse')
    model.summary()
    Best_RMSE=100000000   #Assigning a large number 
    start_time=time.time()
    for run in range(Num_Exp):
        print("Experiment",run+1,"in progress")
        # fit model
        model.fit(x_train, y_train, epochs=Epochs,batch_size=batch_size, verbose=0, shuffle=False, callbacks = [early_stopping_callback])
        y_predicttrain = model.predict(x_train)
        y_predicttrain = np.squeeze(y_predicttrain,axis=-1)
        y_predicttest = model.predict(x_test)
        y_predicttest = np.squeeze(y_predicttest,axis=-1)
        train_acc[run] = rmse( y_predicttrain,y_train) 
        test_acc[run] = rmse( y_predicttest, y_test) 
        if test_acc[run]<Best_RMSE:
            Best_RMSE=test_acc[run]
            Best_Predict_Test=y_predicttest
        for j in range(n_steps_out):
            Step_RMSE[run][j]=rmse(y_predicttest[:,j], y_test[:,j])
            
    print("Total time for",Num_Exp,"experiments",time.time()-start_time)
    return train_acc,test_acc,Step_RMSE,Best_Predict_Test.reshape(y_test.shape[0], y_test.shape[1])

def Plot_Mean(name,Overall_Analysis,n_steps_out):
  labels = ['Train','Test']
  LSTM=[Overall_Analysis[0][0],Overall_Analysis[0][5]]
  Bi_LSTM=[Overall_Analysis[1][0],Overall_Analysis[1][5]]
  EN_DC=[Overall_Analysis[2][0],Overall_Analysis[2][5]]
  
  yer1=np.array([Overall_Analysis[0][3]-Overall_Analysis[0][0],Overall_Analysis[0][8]-Overall_Analysis[0][5]])
  yer2=np.array([Overall_Analysis[1][3]-Overall_Analysis[1][0],Overall_Analysis[1][8]-Overall_Analysis[1][5]])
  yer3=np.array([Overall_Analysis[2][3]-Overall_Analysis[2][0],Overall_Analysis[2][8]-Overall_Analysis[2][5]])
 
  width = 0.25  # the width of the bars
  Plot(name,labels,width,LSTM,Bi_LSTM,EN_DC,yer1,yer2,yer3,"","RMSE","Train&Test_RMSE_Mean_Comparison",4)

def Plot_Step_RMSE_Mean(name,Overall_Analysis,n_steps_out):
    
    LSTM=Overall_Analysis[0,10:n_steps_out*5+10:5]
    Bi_LSTM=Overall_Analysis[1,10:n_steps_out*5+10:5]
    EN_DC=Overall_Analysis[2,10:n_steps_out*5+10:5]
    
    yer1=np.subtract(Overall_Analysis[0,13:n_steps_out*5+10:5],LSTM)
    print(yer1)
    yer2=np.subtract(Overall_Analysis[1,13:n_steps_out*5+10:5],Bi_LSTM)
    yer3=np.subtract(Overall_Analysis[2,13:n_steps_out*5+10:5],EN_DC)
    
    labels = []
    for j in range(n_steps_out):
        labels=np.concatenate((labels,[str(j+1)]))
    width = 0.3  # the width of the bars
    Plot(name,labels,width,LSTM,Bi_LSTM,EN_DC,yer1,yer2,yer3,"Steps","RMSE","Step_RMSE_Comparison",2)
    

def Plot(name,labels,width,LSTM,Bi_LSTM,EN_DC,yer1,yer2,yer3,xlabel,ylabel,Gname,cap):
    r1 = np.arange(len(labels))
    r2 = [x + width for x in r1]
    r3 = [x + width for x in r2]

    fig = plt.figure(figsize=(4,4))
    ax = plt.subplot()
    # fig, ax = plt.subplots()
  
    rects1 = ax.bar(r1, LSTM, width,edgecolor = 'black', yerr=yer1,capsize=cap,  label='LSTM')
    rects2 = ax.bar(r2, Bi_LSTM, width,edgecolor = 'black', yerr=yer2,capsize=cap,  label='BD-LSTM')
    rects3 = ax.bar(r3, EN_DC, width,edgecolor = 'black', yerr=yer3,capsize=cap,  label='ED-LSTM')    
    plt.xlabel(xlabel, fontsize = 18)
    plt.ylabel(ylabel, fontsize = 18)
    plt.xticks([r + width for r in range(len(LSTM))], labels)
    
    plt.setp(ax.get_xticklabels(), fontsize=14)
    plt.setp(ax.get_yticklabels(), fontsize=14)
    
    
    ax.legend()
    fig.tight_layout()
    plt.savefig("/content/drive/My Drive/covid project/Model/Results/Multivariate/NEW_RESULTS_TESTING/Maharashtra/"+name+"_"+Gname+".png",dpi=300)
    plt.show()

### TRAINING DATASET ###
df0 = pd.read_csv('/content/drive/My Drive/covid project/Data/Processed_Data/moving_avg/train_Delhi.csv')
df1 = pd.read_csv('/content/drive/My Drive/covid project/Data/Processed_Data/moving_avg/train_Gujarat.csv')
df2 = pd.read_csv('/content/drive/My Drive/covid project/Data/Processed_Data/moving_avg/train_Haryana.csv')
df3 = pd.read_csv('/content/drive/My Drive/covid project/Data/Processed_Data/moving_avg/train_Karnataka.csv')
df4 = pd.read_csv('/content/drive/My Drive/covid project/Data/Processed_Data/moving_avg/train_Madhya Pradesh.csv')
df5 = pd.read_csv('/content/drive/My Drive/covid project/Data/Processed_Data/moving_avg/train_Maharashtra.csv')
df6 = pd.read_csv('/content/drive/My Drive/covid project/Data/Processed_Data/moving_avg/train_Rajasthan.csv')
df7 = pd.read_csv('/content/drive/My Drive/covid project/Data/Processed_Data/moving_avg/train_Tamil Nadu.csv')
df8 = pd.read_csv('/content/drive/My Drive/covid project/Data/Processed_Data/moving_avg/train_Uttar Pradesh.csv')
df9 = pd.read_csv('/content/drive/My Drive/covid project/Data/Processed_Data/moving_avg/train_West Bengal.csv')
dft = pd.read_csv('/content/drive/My Drive/covid project/Data/Processed_Data/moving_avg/train_Totals.csv')
dfr = pd.read_csv('/content/drive/My Drive/covid project/Data/Processed_Data/moving_avg/train_Rest of India.csv')

### TESTING DATASET ###

df00 = pd.read_csv('/content/drive/My Drive/covid project/Data/Processed_Data/moving_avg/test_Delhi.csv')
df10 = pd.read_csv('/content/drive/My Drive/covid project/Data/Processed_Data/moving_avg/test_Gujarat.csv')
df20 = pd.read_csv('/content/drive/My Drive/covid project/Data/Processed_Data/moving_avg/test_Haryana.csv')
df30 = pd.read_csv('/content/drive/My Drive/covid project/Data/Processed_Data/moving_avg/test_Karnataka.csv')
df40 = pd.read_csv('/content/drive/My Drive/covid project/Data/Processed_Data/moving_avg/test_Madhya Pradesh.csv')
df50 = pd.read_csv('/content/drive/My Drive/covid project/Data/Processed_Data/moving_avg/test_Maharashtra.csv')
df60 = pd.read_csv('/content/drive/My Drive/covid project/Data/Processed_Data/moving_avg/test_Rajasthan.csv')
df70 = pd.read_csv('/content/drive/My Drive/covid project/Data/Processed_Data/moving_avg/test_Tamil Nadu.csv')
df80 = pd.read_csv('/content/drive/My Drive/covid project/Data/Processed_Data/moving_avg/test_Uttar Pradesh.csv')
df90 = pd.read_csv('/content/drive/My Drive/covid project/Data/Processed_Data/moving_avg/test_West Bengal.csv')
dft0 = pd.read_csv('/content/drive/My Drive/covid project/Data/Processed_Data/moving_avg/test_Totals.csv')
dfr0 = pd.read_csv('/content/drive/My Drive/covid project/Data/Processed_Data/moving_avg/test_Rest of India.csv')

dict = {'df0':"Delhi",'df1':"Gujarat",
        'df2':"Haryana",'df3':"Karnataka",
        'df4':"Madhya Pradesh",'df5':"Maharashtra",
        'df6':"Rajasthan",'df7':"Tamil Nadu",
        'df8':"Uttar Pradesh",'df9':"West Bengal",
        'dft':"All India", 'dfr':"Rest Of India"}
#print(dict)  

tup = [('df0',df0),('df1',df1),
       ('df2',df2),('df3',df3),
       ('df4',df4),('df5',df5),
       ('df6',df6),('df7',df7),
       ('df8',df8),('df9',df9),
       ('dft',dft),('dfr',dfr)]

trip_train = [[df5,df1,df4,df8,df0],[dft,df0,df5,dfr],[df0,df6,df8,df2],[df1,df6,df4],[df6,df1,df4],[df8,df0,df4]]
trip_test = [[df50,df10,df40,df80,df00],[dft0,df00,df50,dfr0],[df00,df60,df80,df20],[df10,df60,df40],[df60,df10,df40],[df80,df00,df40]]

#print(tup)

def get_state(df):
  for i in range(len(tup)):
    if(df.equals(tup[i][1])):
      return dict[tup[i][0]]

# def main():
    
n_steps_in, n_steps_out = 6,4
Overall_Analysis=np.zeros([3,10+n_steps_out*5])
for i in range(0,1):
    # problem=i
    # if problem ==1:
        # x_train,x_test,y_train,y_test = processing_data(trip_train[i][0],trip_train[i][1],trip_train[i][2],trip_test[i][0],
        #                                             trip_test[i][1],trip_test[i][2],n_steps_in,n_steps_out)
        # TrainData = pd.read_csv('/content/drive/My Drive/covid project/Data/Processed_Data/train_Totals.csv',index_col = 0)
        # TrainData = TrainData.values
        # TestData = pd.read_csv('/content/drive/My Drive/covid project/Data/Processed_Data/test_Totals.csv',index_col = 0)
        # TestData = TestData.values
        # name= get_state(trip_train[i][0])

    # x_train = TrainData[:,0:n_steps_in]
    # y_train = TrainData[:,n_steps_in : n_steps_in+n_steps_out ]
    # x_test = TestData[:,0:n_steps_in]
    # y_test = TestData[:,n_steps_in : n_steps_in+n_steps_out]
    #No. of experiments

    # 100 100
    # 200 100
    Num_Exp=32
    batch_size = 10
    name= get_state(trip_train[i][0])
    print(name)
    # for epoch in range (10,50):
      # for hidden in range (30,50):
    Hidden= 32
    Epochs= 1000
    TrainRMSE_mean=np.zeros(4)
    TestRMSE_mean=np.zeros(4)
    TrainRMSE_Std=np.zeros(4)
    TestRMSE_Std=np.zeros(4)
    Step_RMSE_mean=np.zeros([4,n_steps_out])
    train_acc=np.zeros(Num_Exp)
    test_acc=np.zeros(Num_Exp)
    Step_RMSE=np.zeros([Num_Exp,n_steps_out])
    print("hii......",len(trip_train[i][3]))
    x_train,x_test,y_train,y_test = processing_data(trip_train[i][0],trip_train[i][1],trip_train[i][2],trip_train[i][3],trip_test[i][0],
                                                    trip_test[i][1],trip_test[i][2],trip_test[i][3],n_steps_in,n_steps_out)

    for k in range(1,4):
        method=k
        if method ==1:
            train_acc,test_acc,Step_RMSE,Best_Predict_Test=MODEL_LSTM(x_train,x_test,y_train,y_test,Num_Exp,Epochs,Hidden,batch_size,n_steps_in,n_steps_out)
            Mname="MODEL_LSTM"
        if method ==2:
            train_acc,test_acc,Step_RMSE,Best_Predict_Test=MODEL_Bi_LSTM(x_train,x_test,y_train,y_test,Num_Exp,Epochs,Hidden,batch_size,n_steps_in,n_steps_out)
            Mname="MODEL_Bi_LSTM"
        if method ==3:
            train_acc,test_acc,Step_RMSE,Best_Predict_Test=MODEL_EN_DC(x_train,x_test,y_train,y_test,Num_Exp,Epochs,Hidden,batch_size,n_steps_in,n_steps_out)
            Mname="MODEL_EN_DC"
            

        print(Mname)

        arr = np.dstack((train_acc,test_acc))
        arr=arr.reshape(Num_Exp,2)
        arr=np.concatenate((arr,Step_RMSE), axis=1)
        arr=arr.reshape(Num_Exp,2+n_steps_out)
        
        ExpIndex=np.array([])
        for j in range(Num_Exp):
            ExpIndex=np.concatenate((ExpIndex,["Exp"+str(j+1)]))

        TrainRMSE_mean[k-1]=np.mean(train_acc)
        TestRMSE_mean[k-1]=np.mean(test_acc)
        TrainRMSE_Std[k-1]=np.std(train_acc)
        TestRMSE_Std[k-1]=np.std(test_acc)
        ExpIndex1=['TrainRMSE','TestRMSE']
        for j in range(n_steps_out):
          Step_RMSE_mean[k-1][j]=np.mean(Step_RMSE[:,j])
          ExpIndex1=np.concatenate((ExpIndex1,["Step"+str(j+1)]))
            
        arr=np.round_(arr, decimals = 5) 
        arr = pd.DataFrame(arr, index = ExpIndex , columns = ExpIndex1)
        print(arr)
        arr.to_csv("/content/drive/My Drive/covid project/Model/Results/Multivariate/NEW_RESULTS_TESTING/"+name+"/"+Mname+"/ExpAnalysis_" + str(Epochs) + '_' + str(Hidden) + ".csv")
        print(arr)
        
        Train_Mean=np.mean(train_acc)
        Train_Std=np.std(train_acc)
        Train_CI_LB= Train_Mean-1.96*(Train_Std/np.sqrt(Num_Exp))
        Train_CI_UB= Train_Mean+1.96*(Train_Std/np.sqrt(Num_Exp))
        
        Test_Mean=np.mean(test_acc)
        Test_Std=np.std(test_acc)
        Test_CI_LB= Test_Mean-1.96*(Test_Std/np.sqrt(Num_Exp))
        Test_CI_UB= Test_Mean+1.96*(Test_Std/np.sqrt(Num_Exp))
        
        Overall_Analysis[(k-1)][0]=Train_Mean
        Overall_Analysis[(k-1)][1]=Train_Std
        Overall_Analysis[(k-1)][2]=Train_CI_LB
        Overall_Analysis[(k-1)][3]=Train_CI_UB
        Overall_Analysis[(k-1)][4]=np.min(train_acc)
        Overall_Analysis[(k-1)][5]=Test_Mean
        Overall_Analysis[(k-1)][6]=Test_Std
        Overall_Analysis[(k-1)][7]=Test_CI_LB
        Overall_Analysis[(k-1)][8]=Test_CI_UB
        Overall_Analysis[(k-1)][9]=np.min(test_acc)
        print(Overall_Analysis.shape)
        print("YOOOOO")
        
        arr1 = np.vstack(([Train_Mean,Train_Std,Train_CI_LB,Train_CI_UB,np.min(train_acc),np.max(train_acc)],[Test_Mean,Test_Std,Test_CI_LB,Test_CI_UB,np.min(test_acc),np.max(test_acc)]))
        
        for j in range(n_steps_out):
            Step_mean = np.mean(Step_RMSE[:,j])
            Step_std = np.std(Step_RMSE[:,j])
            Step_min = np.min(Step_RMSE[:,j])
            Step_CI_LB= Step_mean-1.96*(Step_std/np.sqrt(Num_Exp))
            Step_CI_UB= Step_mean+1.96*(Step_std/np.sqrt(Num_Exp))
            arr1=np.vstack((arr1,[Step_mean,Step_std,Step_CI_LB,Step_CI_UB,Step_min,np.max(Step_RMSE[:,j])]))
            Overall_Analysis[(k-1)][5*j+10]= Step_mean
            Overall_Analysis[(k-1)][5*j+11]= Step_std
            Overall_Analysis[(k-1)][5*j+12]= Step_CI_LB
            Overall_Analysis[(k-1)][5*j+13]= Step_CI_UB
            Overall_Analysis[(k-1)][5*j+14]= Step_min
        arr1=np.round_(arr1, decimals = 5) 
        arr1 = pd.DataFrame(arr1, index=ExpIndex1, columns = ['Mean','Standard Deviation','CI_LB','CI_UB','Min','Max'])
        print(arr1)
        arr1.to_csv("/content/drive/My Drive/covid project/Model/Results/Multivariate/NEW_RESULTS_TESTING/"+name+"/"+Mname+"/OverallAnalysis_" + str(Epochs) + '_' + str(Hidden) + ".csv")
        
        x_data=np.linspace(0,y_test.shape[0], num=y_test.shape[0])
        
        from sklearn.externals import joblib
        scaler_filename = "/content/drive/My Drive/covid project/Data/scalars/Maharashtra_moving"
        scaler = joblib.load(scaler_filename) 

        for j in range(n_steps_out):
            fig = plt.figure()
            ax = plt.subplot(111)
            test_inversed = scaler.inverse_transform(np.reshape(y_test[:,j],(len(y_test[:,j]),1)))
            print ("Inversed Mapping of Tests")
            print (x_data)
            test_inversed_list = []
            for lis in test_inversed:
              test_inversed_list.append(lis[0])
            predict_inversed = scaler.inverse_transform(np.reshape(Best_Predict_Test[:,j],(len(Best_Predict_Test[:,j]),1)))
            predict_inversed_list = []
            for lis in predict_inversed:
              predict_inversed_list.append(lis[0])
            w = 0.4
            ax.bar(x_data-w, test_inversed_list, label="Actual", color='maroon', align='center', width =0.4)
            ax.bar(x_data, predict_inversed_list, label='Predicted', align='center', width = 0.4)
            plt.ylabel('Daily New cases') 
            plt.xlabel('Time (samples)') 
            plt.title('Actual vs Predicted')
            plt.legend()
            plt.savefig("/content/drive/My Drive/covid project/Model/Results/Multivariate/NEW_RESULTS_TESTING/"+name+"/"+Mname+'/pred_Step_'+str(j+1)+'_' + str(Epochs) + '_' + str(Hidden) + '.png',dpi=300) 
            plt.show()
            plt.close()

    #Plot mean of train_RMSE and test_RMSE
    #Plot Std of train_RMSE and test_RMSE
    Plot_Mean(name + '_' + str(Epochs) + '_' + str(Hidden),Overall_Analysis[0:3,:],n_steps_out)
    #Plot Step wise RMSE mean for different methods
    Plot_Step_RMSE_Mean(name + '_' + str(Epochs) + '_' + str(Hidden),Overall_Analysis[0:3,:],n_steps_out)
        
# if __name__ == "__main__": main()

#Plot mean of train_RMSE and test_RMSE
#Plot Std of train_RMSE and test_RMSE
Plot_Mean(name + '_' + str(Epochs) + '_' + str(Hidden),Overall_Analysis[0:3,:],n_steps_out)
#Plot Step wise RMSE mean for different methods
Plot_Step_RMSE_Mean(name + '_' + str(Epochs) + '_' + str(Hidden),Overall_Analysis[0:3,:],n_steps_out)

